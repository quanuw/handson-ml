{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with 1 million instances?\\nDepth of a Decision Tree is N-1 where N is the number of training samples. You can derive this by considering that the least effective split would be peeling off one training example per node.\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with 1 million instances?\n",
    "Depth of a Decision Tree is N-1 where N is the number of training samples. You can derive this by considering that the least effective split would be peeling off one training example per node.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?\\nGenerally a nodes Gini umpurity is lower than its parents because the CART traning algorithm uses\\na cost function that produces the purest subsets weighted by their size.\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?\n",
    "Generally a nodes Gini umpurity is lower than its parents because the CART traning algorithm uses\n",
    "a cost function that produces the purest subsets weighted by their size.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?\\nYes.\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?\n",
    "Yes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?\\nNo, Decision Trees don't require feature scaling.\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?\n",
    "No, Decision Trees don't require feature scaling.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5. If it takes one hour to train a Decision Tree on a training set containing 1 million instances, roughly how much time will it take to train another Decision Tree on a training set containing 10 million instances?\\nThe training complexity is O(n*mlog(m)) where m is the number of samples. So 10,000,000 will take ~11.7 hours to train.\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "5. If it takes one hour to train a Decision Tree on a training set containing 1 million instances, roughly how much time will it take to train another Decision Tree on a training set containing 10 million instances?\n",
    "The training complexity is O(n*mlog(m)) where m is the number of samples. So 10,000,000 will take ~11.7 hours to train.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n6. If your training set contains 100,000 instances, will setting presort=True speed up training?\\nNo, presort will only help if training sets have less than a few thousand instances.\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "6. If your training set contains 100,000 instances, will setting presort=True speed up training?\n",
    "No, presort will only help if training sets have less than a few thousand instances.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.00629982,  0.19298109],\n",
      "       [ 1.00077558, -0.12432866],\n",
      "       [-1.85519594, -0.32988076],\n",
      "       ..., \n",
      "       [-0.50473235, -0.22363531],\n",
      "       [-0.88224129,  0.307626  ],\n",
      "       [-0.81146457,  1.08205398]]), array([0, 0, 0, ..., 0, 0, 0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "moons_data = make_moons(n_samples=10000, noise=0.4)\n",
    "print(moons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62596106  0.10727495]\n",
      " [ 0.17685224  0.71787486]\n",
      " [ 1.76932921 -0.2541071 ]\n",
      " ..., \n",
      " [ 0.11746472  0.22361804]\n",
      " [ 1.06325571  0.47634452]\n",
      " [ 0.71017107  0.16983526]]\n",
      "[0 0 1 ..., 1 1 0]\n",
      "[[ 0.27165539  0.15381178]\n",
      " [-0.71113266  0.43008922]\n",
      " [-0.73240298  0.68191689]\n",
      " ..., \n",
      " [-0.10878564  1.0767956 ]\n",
      " [-0.63085077  0.55958764]\n",
      " [ 0.58092708  1.11959262]]\n",
      "[1 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = moons_data[0]\n",
    "y = moons_data[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 4, 8, 16, 32], 'max_leaf_nodes': [2, 4, 8, 16, 32, 64, 128]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "params = {'max_depth':[1, 2, 4, 8, 16, 32], 'max_leaf_nodes':[2, 4, 8, 16, 32, 64, 128]}\n",
    "clf = GridSearchCV(tree_clf, params, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'max_leaf_nodes': 32}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.86      1655\n",
      "          1       0.88      0.83      0.85      1645\n",
      "\n",
      "avg / total       0.86      0.86      0.86      3300\n",
      "\n",
      "0.857575757576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "# accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quanu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=1000, train_size=.01, random_state=0)\n",
    "\n",
    "n_trees = 1000\n",
    "mini_sets = []\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=16, max_leaf_nodes=32)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    X_mini_train = X[train_index]\n",
    "    y_mini_train = y[train_index]\n",
    "    mini_sets.append((X_mini_train, y_mini_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "forest = [clone(clf.best_estimator_) for _ in range(n_trees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79429939393939386"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "print(Y_pred)\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86848484848484853"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
